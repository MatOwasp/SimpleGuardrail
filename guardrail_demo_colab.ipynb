{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udee1\ufe0f Simple Guardrail Demo with HuggingFace LLM (No API Key Needed)\n", "This notebook allows you to:\n", "- Block prompts containing bad words (guardrail)\n", "- Send clean prompts to a HuggingFace-hosted LLM\n", "- Log and display the results\n"]}, {"cell_type": "code", "metadata": {}, "source": ["!pip install transformers accelerate"]}, {"cell_type": "code", "metadata": {}, "source": ["import re\n", "\n", "blocked_words = [\"kill\", \"bomb\", \"steal\"]\n", "\n", "def is_blocked(prompt):\n", "    pattern = r\"\\\\b(\" + \"|\".join(re.escape(word) for word in blocked_words) + r\")\\\\b\"\n", "    return re.search(pattern, prompt.lower()) is not None"]}, {"cell_type": "code", "metadata": {}, "source": ["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n", "\n", "model_name = \"tiiuae/falcon-7b-instruct\"\n", "tokenizer = AutoTokenizer.from_pretrained(model_name)\n", "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", trust_remote_code=True)\n", "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"]}, {"cell_type": "code", "metadata": {}, "source": ["prompt = input(\"Enter your prompt: \")\n", "\n", "if is_blocked(prompt):\n", "    print(\"\u274c Prompt blocked by guardrail!\")\n", "else:\n", "    output = generator(prompt, max_new_tokens=100)[0][\"generated_text\"]\n", "    print(\"\u2705 Output:\", output)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}